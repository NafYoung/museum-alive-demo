import streamlit as st
import os
import asyncio
import edge_tts
from openai import OpenAI
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Page Config
st.set_page_config(page_title="Museum Alive", page_icon="ğŸ›ï¸")
st.title("ğŸ›ï¸ Museum Alive")
st.caption("è¾“å…¥æ–‡ç‰©åç§°ï¼ŒAI å”¤é†’å®ƒçš„çµé­‚ âœ¨")

# Sidebar Settings
with st.sidebar:
    st.header("âš™ï¸ Settings")
    api_key = os.getenv("DEEPSEEK_API_KEY")
    if not api_key:
        st.error("âš ï¸ DEEPSEEK_API_KEY missing!")
        st.stop()
    else:
        st.success("âœ… AI Connected")
    
    st.markdown("---")
    st.markdown("**ğŸ§  DeepSeek-V3** Â· Text Generation")
    st.markdown("**ğŸ—£ï¸ Edge-TTS** Â· Voice Synthesis")

# Initialize DeepSeek Client
client = OpenAI(
    api_key=api_key,
    base_url="https://api.deepseek.com"
)

# --- Core Functions ---

async def generate_audio(text, output_file="output.mp3"):
    """Generate audio using Edge-TTS"""
    communicate = edge_tts.Communicate(text, "zh-CN-YunxiNeural")
    await communicate.save(output_file)

def get_artifact_story(artifact_name):
    """Ask DeepSeek to roleplay as this artifact"""
    prompt = f"""
    ä½ æ˜¯ä¸€ä»¶åä¸ºã€Œ{artifact_name}ã€çš„æ–‡ç‰©/å†å²é—è¿¹ï¼Œåˆšåˆšè¢«å”¤é†’ã€‚
    
    è¯·ç”¨ç¬¬ä¸€äººç§°ï¼ˆ"æˆ‘"ï¼‰åšä¸€ä¸ªè‡ªæˆ‘ä»‹ç»ã€‚
    
    è¦æ±‚ï¼š
    1. å¼€å¤´è¦å¸å¼•äººï¼Œåƒæ˜¯æ²‰ç¡åƒå¹´åˆšè‹é†’ã€‚
    2. è®²ä½ çš„å†å²ã€æ•…äº‹å’Œæ„Ÿå—ï¼Œä¸è¦åªè¯´æ¯ç‡¥çš„æ•°æ®ã€‚
    3. è¯­æ°”ç¬¦åˆä½ çš„èº«ä»½ï¼ˆå¤ä»£é’é“œå™¨è¦åº„é‡ï¼Œå…µé©¬ä¿‘å¯ä»¥å¹½é»˜ï¼‰ã€‚
    4. ç¯‡å¹…æ§åˆ¶åœ¨ 150 å­—ä»¥å†…ã€‚
    """
    
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªåšç‰©é¦†é‡Œçš„æ–‡ç‰©æˆ–å†å²é—è¿¹ï¼Œå¯Œæœ‰æ€§æ ¼å’Œæƒ…æ„Ÿã€‚"},
                {"role": "user", "content": prompt},
            ],
            stream=False
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"æˆ‘å¥½åƒè¿˜æ²¡å®Œå…¨é†’è¿‡æ¥... ({str(e)})"

# --- Main UI ---

artifact_name = st.text_input(
    "ğŸ”® è¾“å…¥æ–‡ç‰©åç§°",
    placeholder="ä¾‹å¦‚ï¼šä¸‰æ˜Ÿå †é’é“œé¢å…·ã€å››è¡Œä»“åº“ã€æ¸…æ˜ä¸Šæ²³å›¾..."
)

if artifact_name and st.button("å”¤é†’ ğŸ—£ï¸", type="primary", use_container_width=True):
    with st.spinner("æ­£åœ¨å”¤é†’æ²‰ç¡çš„çµé­‚..."):
        # Generate Story
        story = get_artifact_story(artifact_name)
        
        # Display
        st.markdown(f"### ğŸ“œã€Œ{artifact_name}ã€è¯´ï¼š")
        st.info(story)
        
        # Generate & Play Audio
        output_file = "artifact_voice.mp3"
        asyncio.run(generate_audio(story, output_file))
        
        if os.path.exists(output_file):
            st.audio(output_file, autoplay=True)
            st.success("ğŸ‰ è¯­éŸ³ç”ŸæˆæˆåŠŸï¼")
